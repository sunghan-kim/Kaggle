{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SAMPLE_PATH = '../../input/fasttext-crawl-300d-2m/embedding-model-sample.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr) :\n",
    "    return word, np.asarray(arr, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(embed_dir=EMB_SAMPLE_PATH) :\n",
    "    embedding_index = dict(get_coefs(*o.strip().split(' ')) for o in tqdm(open(embed_dir)))\n",
    "    return embedding_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:00, 3675.70it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = load_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', 'the', '.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(embeddings_index.keys())[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([300.], dtype=float32),\n",
       " array([-2.820e-02, -5.570e-02, -4.510e-02, -4.340e-02,  7.120e-02,\n",
       "        -8.550e-02, -1.085e-01, -5.610e-02, -4.523e-01, -2.020e-02,\n",
       "         9.750e-02,  1.047e-01,  1.962e-01, -6.930e-02,  2.130e-02,\n",
       "        -2.350e-02,  1.336e-01, -4.200e-02, -5.640e-02, -7.980e-02,\n",
       "         4.240e-02, -4.090e-02, -5.360e-02, -2.520e-02,  1.350e-02,\n",
       "         6.400e-03,  1.235e-01,  4.610e-02,  1.200e-02, -3.720e-02,\n",
       "         6.500e-02,  4.100e-03, -1.074e-01, -2.630e-02,  1.133e-01,\n",
       "        -2.900e-03,  6.710e-02,  1.065e-01,  2.340e-02, -1.600e-02,\n",
       "         7.000e-03,  4.355e-01, -7.520e-02, -4.328e-01,  4.570e-02,\n",
       "         6.040e-02, -7.400e-02, -5.500e-03, -8.900e-03, -2.926e-01,\n",
       "        -5.450e-02, -1.519e-01,  9.900e-02, -1.930e-02, -5.000e-03,\n",
       "         5.110e-02,  4.040e-02,  1.023e-01, -1.280e-02,  4.880e-02,\n",
       "        -1.567e-01, -7.590e-02, -1.900e-02,  1.442e-01,  4.700e-03,\n",
       "        -1.860e-02,  1.400e-02, -3.850e-02, -8.530e-02,  1.572e-01,\n",
       "         1.770e-01,  8.400e-03, -2.500e-02, -1.145e-01, -6.630e-02,\n",
       "        -1.244e-01, -3.977e-01, -1.240e-02, -4.586e-01, -2.200e-02,\n",
       "         5.746e-01,  2.180e-02, -7.540e-02,  9.900e-03,  3.970e-02,\n",
       "        -1.540e-02,  4.240e-02, -1.500e-02, -1.600e-03,  3.050e-02,\n",
       "         1.010e-02,  2.266e-01,  1.394e-01,  1.890e-02,  6.900e-03,\n",
       "         3.940e-02,  3.550e-02, -1.110e-02, -6.870e-02, -7.800e-03,\n",
       "         2.240e-02,  8.170e-02, -1.949e-01,  1.000e-04,  4.047e-01,\n",
       "        -2.370e-02, -6.560e-02, -6.840e-02,  2.330e-02,  4.380e-02,\n",
       "         1.203e-01, -2.760e-02,  4.160e-02,  1.140e-02, -4.529e-01,\n",
       "         1.538e-01,  1.323e-01, -1.860e-02, -9.140e-02, -3.120e-02,\n",
       "         1.051e-01,  2.120e-02,  7.980e-02, -1.040e-02, -2.060e-02,\n",
       "        -2.500e-03,  4.300e-03, -3.780e-02,  2.689e-01,  7.470e-02,\n",
       "        -4.180e-02, -4.800e-03, -3.870e-02,  4.320e-02,  1.704e-01,\n",
       "         6.140e-02,  9.050e-02, -4.360e-02, -1.410e-02, -3.150e-02,\n",
       "         2.760e-02,  1.510e-02, -1.030e-02, -2.660e-02, -5.120e-02,\n",
       "        -4.080e-02, -6.510e-02,  6.620e-02, -9.360e-02,  1.371e-01,\n",
       "         4.580e-02, -1.366e-01, -7.500e-03, -1.040e-02, -7.320e-02,\n",
       "         1.205e-01,  1.035e-01,  1.060e-02, -3.170e-02, -3.160e-02,\n",
       "         6.639e-01, -2.200e-03, -1.343e-01,  1.440e-02, -3.380e-02,\n",
       "         3.400e-03, -4.290e-02, -8.210e-02,  3.700e-03,  1.029e-01,\n",
       "        -2.040e-02, -2.690e-02,  5.200e-03, -1.034e-01,  1.068e-01,\n",
       "         1.210e-02,  9.800e-02, -4.580e-02,  1.990e-02, -1.320e-02,\n",
       "         1.936e-01, -2.130e-02,  2.090e-02, -2.500e-03,  4.160e-02,\n",
       "        -3.370e-02,  5.160e-02, -1.014e-01,  2.030e-02,  1.980e-02,\n",
       "        -3.050e-02, -3.130e-02,  5.430e-02, -1.060e-02,  1.441e-01,\n",
       "        -1.780e-02, -6.270e-02,  4.750e-02,  3.520e-02, -2.540e-02,\n",
       "        -9.490e-02,  4.010e-02,  3.170e-02,  5.500e-03, -5.360e-02,\n",
       "         1.910e-02, -5.110e-02, -4.090e-02, -3.000e-03,  1.582e-01,\n",
       "         1.080e-02,  5.237e-01,  4.360e-02,  3.060e-02, -3.920e-02,\n",
       "         1.770e-02,  6.900e-03,  6.050e-02,  1.206e-01, -2.160e-02,\n",
       "        -6.330e-02, -2.965e-01,  5.210e-02, -1.500e-02, -2.207e-01,\n",
       "        -6.420e-02, -9.060e-02, -1.210e-02,  5.690e-02,  9.440e-02,\n",
       "        -6.520e-02, -1.080e-02, -4.770e-02,  2.300e-03,  7.700e-03,\n",
       "        -1.547e-01,  4.630e-02,  6.980e-02, -3.760e-02, -2.910e-02,\n",
       "         3.300e-03, -1.020e-02, -7.430e-02,  8.500e-03,  8.050e-02,\n",
       "        -2.910e-02, -6.740e-02, -5.860e-02, -6.530e-02,  2.830e-02,\n",
       "        -2.550e-02,  8.690e-02, -8.680e-02,  9.000e-03,  3.245e-01,\n",
       "        -5.730e-02, -2.890e-02,  4.700e-02, -1.170e-02,  1.740e-02,\n",
       "         1.320e-02, -2.260e-02, -6.640e-02,  1.880e-02,  2.630e-02,\n",
       "         1.110e-02, -4.900e-03, -6.560e-02,  2.950e-02,  4.350e-02,\n",
       "         2.900e-02,  1.163e-01,  4.480e-02, -1.139e-01, -5.530e-02,\n",
       "        -5.280e-02,  1.745e-01, -1.460e-02, -1.308e-01, -6.070e-02,\n",
       "        -1.340e-02,  7.810e-02,  3.780e-02,  2.280e-02, -7.280e-02,\n",
       "        -5.900e-03,  1.580e-02, -1.410e-02, -2.000e-04,  1.930e-02,\n",
       "        -1.480e-02, -4.630e-02,  4.440e-02,  3.034e-01,  1.020e-01,\n",
       "        -8.710e-02,  3.170e-02, -3.700e-02, -7.250e-02, -4.200e-03],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(embeddings_index.values())[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shkim\\AppData\\Local\\conda\\conda\\envs\\python36\\lib\\site-packages\\numpy\\lib\\arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "TEXT_COL = 'comment_text'\n",
    "\n",
    "train = pd.read_csv('../../input/train.csv', index_col='id')\n",
    "test = pd.read_csv('../../input/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting tokenizer\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import gc\n",
    "\n",
    "maxlen = 220\n",
    "max_features = 100000\n",
    "embed_size = 300\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features, lower=True)\n",
    "\n",
    "print('fitting tokenizer')\n",
    "\n",
    "tokenizer.fit_on_texts(list(train[TEXT_COL]) + list(test[TEXT_COL]))\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((max_features, 300))\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
