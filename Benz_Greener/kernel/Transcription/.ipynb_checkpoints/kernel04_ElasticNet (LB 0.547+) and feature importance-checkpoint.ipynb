{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet (LB 0.547+) and feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[den3b's Kernel](https://www.kaggle.com/den3b81/elasticnet-lb-0-547-and-feature-importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello there everyone!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am new to this competition but it looks like this dataset leads to overfitting problems. In addition, it seems like Mercedes is interested in reducing the dataset to a few meaningful variables. Therefore, I thought it was a good idea to try one of the best linear models I know for tacking overfitting that works also as a feature selection method: **Elastic Nets**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic Nets are essentially a **Lasso/Ridge** hybrid, that entails the minimization of an objective function that includes both **L1** (Lasso) anad **L2** (Ridge) norms. You can find more about ElasticNets [here](http://www.onthelambda.com/2015/08/19/kickin-it-with-elastic-net-regression/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of this notebook it is important to notice that Elastic nets depends on two parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the **`l1_ratio`**, i.e. the tradeoff between the two norms\n",
    "  - l1_ratio = 0 --> Ridge\n",
    "  - l1_ratio = 1 --> Lasso\n",
    "  - 0 < l1_ratio < 1 --> Mix of the two\n",
    "- **`alpha`**, that regulates the amount of penalty applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know that minimizing the L1 norm will force some coefficients to shrink to zero, and that's why Elastic Nets can be used as feature selection techniques. Besides, when there's a high degree of collinearity(동일선상에있음) in the data, the cross-validation procedure used to determine these two parameters will return low l1_ratio since Ridge tends to outperform Lasso in these cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... let's use scikit-learn and see how these methods perform and which features they select!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_df = pd.read_csv('../../input/train.csv')\n",
    "test_df = pd.read_csv('../../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train_y, test ids and unite datasets to perform\n",
    "train_y = train_df['y']\n",
    "train_df.drop('y', axis=1, inplace=True)\n",
    "test_ids = test_df.ID.values\n",
    "all_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "# ...one hot encoding of categorical variables\n",
    "categorical = [\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]\n",
    "\n",
    "for f in categorical :\n",
    "    dummies = pd.get_dummies(all_df[f], prefix=f, prefix_sep='_')\n",
    "    all_df = pd.concat([all_df, dummies], axis=1)\n",
    "    \n",
    "# drop original categorical features\n",
    "all_df.drop(categorical, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature dataset for test and training\n",
    "train_X = all_df.drop([\"ID\"], axis=1).iloc[:len(train_df),:]\n",
    "test_X = all_df.drop([\"ID\"], axis=1).iloc[len(train_df):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>...</th>\n",
       "      <th>X8_p</th>\n",
       "      <th>X8_q</th>\n",
       "      <th>X8_r</th>\n",
       "      <th>X8_s</th>\n",
       "      <th>X8_t</th>\n",
       "      <th>X8_u</th>\n",
       "      <th>X8_v</th>\n",
       "      <th>X8_w</th>\n",
       "      <th>X8_x</th>\n",
       "      <th>X8_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 579 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X10  X11  X12  X13  X14  X15  X16  X17  X18  X19  ...   X8_p  X8_q  X8_r  \\\n",
       "0    0    0    0    1    0    0    0    0    1    0  ...      0     0     0   \n",
       "1    0    0    0    0    0    0    0    0    1    0  ...      0     0     0   \n",
       "2    0    0    0    0    0    0    0    1    0    0  ...      0     0     0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...      0     0     0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...      0     0     0   \n",
       "\n",
       "   X8_s  X8_t  X8_u  X8_v  X8_w  X8_x  X8_y  \n",
       "0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     1     0  \n",
       "3     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 579 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>...</th>\n",
       "      <th>X8_p</th>\n",
       "      <th>X8_q</th>\n",
       "      <th>X8_r</th>\n",
       "      <th>X8_s</th>\n",
       "      <th>X8_t</th>\n",
       "      <th>X8_u</th>\n",
       "      <th>X8_v</th>\n",
       "      <th>X8_w</th>\n",
       "      <th>X8_x</th>\n",
       "      <th>X8_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 579 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X10  X11  X12  X13  X14  X15  X16  X17  X18  X19  ...   X8_p  X8_q  X8_r  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...      0     0     0   \n",
       "1    0    0    0    0    0    0    0    0    0    1  ...      0     0     0   \n",
       "2    0    0    0    0    1    0    0    0    0    0  ...      0     0     0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...      0     0     0   \n",
       "4    0    0    0    0    1    0    0    0    0    0  ...      0     0     0   \n",
       "\n",
       "   X8_s  X8_t  X8_u  X8_v  X8_w  X8_x  X8_y  \n",
       "0     0     0     0     0     1     0     0  \n",
       "1     0     0     0     0     0     0     1  \n",
       "2     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 579 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model deveelopment and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's perform a cross-validation to find the best combination of alpha and l1_ratio\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "\n",
    "cv_model = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, .995, 1],\n",
    "                        eps=0.001,\n",
    "                        n_alphas=100,\n",
    "                        fit_intercept=True,\n",
    "                        normalize=True,\n",
    "                        precompute='auto',\n",
    "                        max_iter=2000,\n",
    "                        tol=0.0001,\n",
    "                        cv=5,\n",
    "                        copy_X=True,\n",
    "                        verbose=0,\n",
    "                        n_jobs=-1,\n",
    "                        positive=False,\n",
    "                        random_state=None,\n",
    "                        selection='cyclic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=None, copy_X=True, cv=5, eps=0.001, fit_intercept=True,\n",
       "       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 0.995, 1], max_iter=2000,\n",
       "       n_alphas=100, n_jobs=-1, normalize=True, positive=False,\n",
       "       precompute='auto', random_state=None, selection='cyclic',\n",
       "       tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.00314540\n",
      "Optimal l1_ratio: 1.000\n",
      "Number of iterations 603\n"
     ]
    }
   ],
   "source": [
    "print('Optimal alpha: %.8f'%cv_model.alpha_)\n",
    "print('Optimal l1_ratio: %.3f'%cv_model.l1_ratio_)\n",
    "print('Number of iterations %d'%cv_model.n_iter_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**l1_ratio = 1**, that means we are just using Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.0031453993038814206, copy_X=True, fit_intercept=True,\n",
       "      l1_ratio=1.0, max_iter=603, normalize=True, positive=False,\n",
       "      precompute=False, random_state=None, selection='cyclic', tol=0.0001,\n",
       "      warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with best parameters from CV\n",
    "model = ElasticNet(l1_ratio=cv_model.l1_ratio_,\n",
    "                   alpha=cv_model.alpha_,\n",
    "                   max_iter=cv_model.n_iter_,\n",
    "                   fit_intercept=True,\n",
    "                   normalize=True)\n",
    "\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5869787709418979\n"
     ]
    }
   ],
   "source": [
    "# r2 score on training dataset\n",
    "print(r2_score(train_y, model.predict(train_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment below if you wnat the predictions on the test dataset (LB 0.547+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_X)\n",
    "df_sub = pd.DataFrame({'ID': test_ids, 'y': preds})\n",
    "df_sub.to_csv('output04_elnet_submission_dummies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the importance of each feature based on the absolute value of their coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 features, reduction of 88.08%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x162e015bb00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = pd.Series(index=train_X.columns,\n",
    "                               data=np.abs(model.coef_))\n",
    "\n",
    "n_selected_features = (feature_importance > 0).sum()\n",
    "print('{0:d} features, reduction of {1:2.2f}%'.format(n_selected_features,\n",
    "                                                      (1-n_selected_features/len(feature_importance))*100))\n",
    "\n",
    "feature_importance.sort_values().tail(30).plot(kind='bar', figsize=(18,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's nice to see how these features compares with those selected by xgboost or other nonlinear methods. Anyway, 88.26% features reduction (with respect to dataset with dummies) looks nice. Besides, the performance on the LB of this linear model seems to be close to those of more sophisticated(복잡한) ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
