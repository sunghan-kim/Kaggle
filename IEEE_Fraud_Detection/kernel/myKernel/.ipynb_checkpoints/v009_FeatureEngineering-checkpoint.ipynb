{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Load Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nprint(os.listdir('../input'))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# 1. Prepare Data"},{"metadata":{},"cell_type":"markdown","source":"## 1.1 Load Datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_t = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\ndf_train_i = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\ndf_test_t = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')\ndf_test_i = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')\nsample_submission = pd.read_csv('../input/sample_submission.csv')\n\nprint('train_transaction의 shape : ', df_train_t.shape)\nprint('train_identity의 shape : ', df_train_i.shape)\nprint('test_transaction의 shape : ', df_test_t.shape)\nprint('test_transaction의 shape : ', df_test_i.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2 Merge Datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train_t.merge(df_train_i, how='left', left_index=True, right_index=True)\ndf_test = df_test_t.merge(df_test_i, how='left', left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3 Divide Features by Categorical and Numerical"},{"metadata":{"trusted":true},"cell_type":"code","source":"# cat_col_t : categorical columns in transaction dataset\ncat_col_t = ['ProductCD','addr1','addr2', 'P_emaildomain', 'R_emaildomain', 'TransactionDT']\ncat_col_t.extend(['card' + str(x) for x in range(1,7)]) # card1 ~ card6\ncat_col_t.extend(['M' + str(x) for x in range(1,10)]) # M1 ~ M9\n\n# cat_col_i : categorical columns in identity dataset\ncat_col_i = ['DeviceType', 'DeviceInfo']\ncat_col_i.extend(['id_' + str(x) for x in range(12, 39)]) # id_12 ~ id_38\n\n# cat_col : categorical columns in transaction and identity dataset\ncat_col = [*cat_col_t, *cat_col_i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# num_col_t : numerical columns in transaction dataset\nnum_col_t = [col for col in list(df_train_t.columns) if col not in [*cat_col_t, 'isFraud']]\n\n# num_col_i : numerical columns in identity dataset\nnum_col_i = [col for col in list(df_train_i.columns) if col not in cat_col_i]\n\n# num_col : numerical columns in transaction and identity dataset\nnum_col =[*num_col_t, *num_col_i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"number of transaction dataset's columns : \", df_train_t.shape[1])\nprint(\"cat_col_t's length : \", len(cat_col_t))\nprint(\"num_col_t's length : \", len(num_col_t))\nprint(\"sum of boths : \", len(cat_col_t) + len(num_col_t))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"number of transaction dataset's columns : \", df_train_i.shape[1])\nprint(\"cat_col_i's length : \", len(cat_col_i))\nprint(\"num_col_i's length : \", len(num_col_i))\nprint(\"sum of boths : \", len(cat_col_i) + len(num_col_i))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Summary of Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_cat_summary(df, features) :\n\n    summary = df[features].dtypes.reset_index()\n    summary.rename(columns={'index': 'Name', 0: 'Dtype'}, inplace=True)\n    summary['DataSets'] = ['transaction' if col in cat_col_t else 'identity' for col in features]\n    summary['NullCnt'] = [df[col].isnull().sum() for col in features]\n    summary['NullRt'] = [np.round((df[col].isnull().sum())/df.shape[0], 2) for col in features]\n    summary['UniqueCnt'] = [df[col].nunique() for col in features]\n    Values = []\n    for col in features :\n        if df[col].nunique() <= 5 :\n            val = list(df[col].value_counts().reset_index()['index'])\n            val.sort()\n            Values.append(', '.join(str(v) for v in val))\n        else :\n            Values.append('-')    \n    summary['Values'] = Values\n    summary['MinValue'] = [df.loc[df[col].notnull(), col].min() for col in features]\n    summary['MaxValue'] = [df.loc[df[col].notnull(), col].max() for col in features]\n    \n    return summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_summary = make_cat_summary(df_train, cat_col)\ncat_summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_num_summary(df, features) :\n    \n    summary = df[features].dtypes.reset_index()\n    summary.rename(columns={'index': 'Name', 0: 'Dtype'}, inplace=True)\n    summary['DataSets'] = ['transaction' if col in num_col_t else 'identity' for col in features]\n    summary['NullCnt'] = [df[col].isnull().sum() for col in features]\n    summary['NullRt'] = [np.round((df[col].isnull().sum())/df.shape[0], 2) for col in features]\n    summary['MinValue'] = [df.loc[df[col].notnull(), col].min() for col in features]\n    summary['Q25'] = [df[col].quantile([0.25]).values[0] for col in features]\n    summary['Q50'] = [df[col].quantile([0.50]).values[0] for col in features]\n    summary['Q75'] = [df[col].quantile([0.75]).values[0] for col in features]\n    summary['MaxValue'] = [df.loc[df[col].notnull(), col].max() for col in features]\n    summary['Mean'] = [df.loc[df[col].notnull(), col].mean() for col in features]\n    summary['Std'] = [df.loc[df[col].notnull(), col].std() for col in features]\n\n    return summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_summary = make_num_summary(df_train, num_col)\nnum_summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# 3. Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"def value_acc_freq(df, col) :\n        \n    df_vc = df[col].value_counts().reset_index()\n    df_vc.rename(columns={'index': 'value', col: 'cnt'}, inplace=True)\n    df_vc['accCntRt'] = df_vc['cnt'].cumsum() / len(df[df[col].notnull()])\n    \n    return df_vc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_to_others(df, col, rate=None, cnt=None) :\n    \n    df_vc = df[col].value_counts().reset_index()\n    df_vc.rename(columns={'index': 'value', col: 'cnt'}, inplace=True)\n    df_vc['accCntRt'] = df_vc['cnt'].cumsum() / len(df[df[col].notnull()])\n    target_list = []\n    \n    if rate != None :\n        target_list = list(df_vc[df_vc['accCntRt'] >= float(rate)]['value'])\n    if cnt != None :\n        target_list = list(df_vc[df_vc['cnt'] < int(10)]['value'])\n        \n    dataType = str(df_vc['value'].values.dtype)\n    replace_value = 'OTHERS'\n    if dataType.find('int') == 0 :\n        replace_value = int(99999)\n    elif dataType.find('float') == 0 :\n        replace_value = float(99999)\n    \n    df.loc[df[col].isin(target_list), col] = replace_value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.1 Categorical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cat_feature_engineering(df) :\n    # addr1\n    replace_to_others(df, 'addr1', rate=0.95)\n\n    # addr2\n    replace_to_others(df, 'addr2', cnt=10)\n\n    # P_emaildomain\n    df.loc[df['P_emaildomain'].str.contains('gmail', na=False), 'P_emaildomain'] = 'GMAIL'\n    df.loc[df['P_emaildomain'].str.contains('yahoo', na=False), 'P_emaildomain'] = 'YAHOO'\n    df.loc[df['P_emaildomain'].str.contains('hotmail', na=False), 'P_emaildomain'] = 'HOTMAIL'\n    df.loc[df['P_emaildomain'].str.contains('live', na=False), 'P_emaildomain'] = 'LIVE'\n    df.loc[df['P_emaildomain'].str.contains('netzero', na=False), 'P_emaildomain'] = 'NETZERO'\n    df.loc[df['P_emaildomain'].str.contains('outlook', na=False), 'P_emaildomain'] = 'OUTLOOK'\n    replace_to_others(df, 'P_emaildomain', cnt=250)\n\n    # R_emaildomain\n    df.loc[df['R_emaildomain'].str.contains('gmail', na=False), 'R_emaildomain'] = 'GMAIL'\n    df.loc[df['R_emaildomain'].str.contains('yahoo', na=False), 'R_emaildomain'] = 'YAHOO'\n    df.loc[df['R_emaildomain'].str.contains('hotmail', na=False), 'R_emaildomain'] = 'HOTMAIL'\n    df.loc[df['R_emaildomain'].str.contains('live', na=False), 'R_emaildomain'] = 'LIVE'\n    df.loc[df['R_emaildomain'].str.contains('netzero', na=False), 'R_emaildomain'] = 'NETZERO'\n    df.loc[df['R_emaildomain'].str.contains('outlook', na=False), 'R_emaildomain'] = 'OUTLOOK'\n    replace_to_others(df, 'R_emaildomain', cnt=80)\n\n    # TransactionDT\n    # Reference : https://www.kaggle.com/shkim4738/extensive-eda-and-modeling-xgb-hyperopt\n    import datetime\n\n    START_DATE = '2017-12-01'\n    startdate = datetime.datetime.strptime(START_DATE, '%Y-%m-%d')\n    df['Date'] = df['TransactionDT'].apply(lambda x : (startdate + datetime.timedelta(seconds=x)))\n\n    df['Weekdays'] = df['Date'].dt.dayofweek\n    df['Hours'] = df['Date'].dt.hour\n    df['Days'] = df['Date'].dt.day\n\n    df.drop(['Date'], axis=1, inplace=True)\n\n    # DeviceInfo\n    df.loc[df['DeviceInfo'].str.contains('SAMSUNG', na=False), 'DeviceInfo'] = 'SAMSUNG'\n    df.loc[df['DeviceInfo'].str.contains('SM', na=False), 'DeviceInfo'] = 'SM'\n    df.loc[df['DeviceInfo'].str.contains('rv', na=False), 'DeviceInfo'] = 'RV'\n    df.loc[df['DeviceInfo'].str.contains('Moto', na=False), 'DeviceInfo'] = 'MOTO'\n    df.loc[df['DeviceInfo'].str.contains('HUAWEI', na=False), 'DeviceInfo'] = 'HUAWEI'\n    df.loc[df['DeviceInfo'].str.contains('Huawei', na=False), 'DeviceInfo'] = 'HUAWEI'\n    df.loc[df['DeviceInfo'].str.contains('LG-', na=False), 'DeviceInfo'] = 'LG'\n    df.loc[df['DeviceInfo'].str.contains('Android', na=False), 'DeviceInfo'] = 'ANDROID'\n    df.loc[df['DeviceInfo'].str.contains('Linux', na=False), 'DeviceInfo'] = 'LINUX'\n    df.loc[df['DeviceInfo'].str.contains('HTC', na=False), 'DeviceInfo'] = 'HTC'\n    df.loc[df['DeviceInfo'].str.contains('Hisense', na=False), 'DeviceInfo'] = 'HISENSE'\n    df.loc[df['DeviceInfo'].str.contains('Blade', na=False), 'DeviceInfo'] = 'BLADE'\n    df.loc[df['DeviceInfo'].str.contains('BLADE', na=False), 'DeviceInfo'] = 'BLADE'\n    df.loc[df['DeviceInfo'].str.contains('ASUS', na=False), 'DeviceInfo'] = 'ASUS'\n    df.loc[df['DeviceInfo'].str.contains('Redmi', na=False), 'DeviceInfo'] = 'REDMI'\n    df.loc[df['DeviceInfo'].str.contains('iOS', na=False), 'DeviceInfo'] = 'iOS'\n    df.loc[df['DeviceInfo'].str.contains('MacOS', na=False), 'DeviceInfo'] = 'MacOS'\n    device = ['SAMSUNG','SM','RV','MOTO','HUAWEI','LG','ANDROID','LINUX','HTC','HISENSE','BLADE','ASUS','REDMI',\n              'Windows','iOS', 'MacOS', 'Trident/7.0']\n    df.loc[(~df['DeviceInfo'].isin(device)) & (df['DeviceInfo'].notnull()), 'DeviceInfo'] = 'OTHERS'\n\n    # id_30\n    df.loc[df['id_30'].str.contains('Windows', na=False), 'id_30'] = 'WINDOWS'\n    df.loc[df['id_30'].str.contains('iOS', na=False), 'id_30'] = 'iOS'\n    df.loc[df['id_30'].str.contains('Mac OS X', na=False), 'id_30'] = 'MacOS'\n    df.loc[df['id_30'].str.contains('Android', na=False), 'id_30'] = 'ANDROID'\n\n    # id_31\n    df.loc[df['id_31'].str.contains('chrome', na=False), 'id_31'] = 'CHROME'\n    df.loc[df['id_31'].str.contains('firefox', na=False), 'id_31'] = 'FIREFOX'\n    df.loc[df['id_31'].str.contains('edge', na=False), 'id_31'] = 'EDGE'\n    df.loc[df['id_31'].str.contains('ie ', na=False), 'id_31'] = 'IE'\n    df.loc[df['id_31'].str.contains('safari', na=False), 'id_31'] = 'SAFARI'\n    df.loc[df['id_31'].str.contains('opera', na=False), 'id_31'] = 'OPERA'\n    df.loc[df['id_31'].str.contains('samsung', na=False), 'id_31'] = 'SAMSUNG'\n    df.loc[df['id_31'].str.contains('Samsung', na=False), 'id_31'] = 'SAMSUNG'\n    df.loc[df['id_31'].str.contains('android', na=False), 'id_31'] = 'ANDROID'\n    df.loc[df['id_31'].str.contains('Android', na=False), 'id_31'] = 'ANDROID'\n    device2 = ['CHROME','FIREFOX','EDGE','IE','SAFARI','OPERA','SAMSUNG','ANDROID']\n    df.loc[(~df['id_31'].isin(device2)) & (df['id_31'].notnull()), 'id_31'] = 'OTHERS'\n\n    # id_33\n    replace_to_others(df, 'id_33', cnt=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_feature_engineering(df_train)\ncat_feature_engineering(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col_t.extend(['Weekdays','Hours','Days'])\ncat_col = [*cat_col_t, *cat_col_i]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2 Numerical Features"},{"metadata":{},"cell_type":"markdown","source":"생략"},{"metadata":{},"cell_type":"markdown","source":"## 3.3 Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col_null_over90 = list(cat_summary.loc[cat_summary['NullRt'] >= float(0.9), 'Name'].values)\nnum_col_null_over90 = list(num_summary.loc[num_summary['NullRt'] >= float(0.9), 'Name'].values)\ncol_null_over90 = [*cat_col_null_over90, *num_col_null_over90]\ncol_null_over90","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.drop(col_null_over90, axis=1)\ndf_test = df_test.drop(col_null_over90, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col = [col for col in cat_col if col not in cat_col_null_over90]\nnum_col = [col for col in num_col if col not in num_col_null_over90]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`sklearn`의 분류기들은 Null 값을 입력인자로 받지 못한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_col :\n    if df_train[col].isnull().sum() != 0 :\n        df_train[col].fillna(value='NaN', inplace=True) # NaN 범주로 결측값 처리","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in num_col :\n    if df_train[col].isnull().sum() != 0 :\n        df_train[col].fillna(df_train[col].mean(), inplace=True) # 평균값으로 결측치 처리","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_col :\n    if col in df_train.columns :\n        le = LabelEncoder()\n        le.fit(list(df_train[col].astype(str).values) + list(df_test[col].astype(str).values))\n        df_train[col] = le.transform(list(df_train[col].astype(str).values))\n        df_test[col] = le.transform(list(df_test[col].astype(str).values))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Set X, y"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = df_train['isFraud']\nX_train = df_train.drop('isFraud', axis=1)\nX_test = df_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.1 Make Validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=1234)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_clf = DecisionTreeClassifier()\ndt_clf.fit(X_train, y_train)\ndt_pred = dt_clf.predict(X_valid)\nprint(\"DecisionTreeClassifier's roc_auc_score : {0:.4f}\".format(roc_auc_score(y_valid, dt_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_clf = RandomForestClassifier()\nrf_clf.fit(X_train, y_train)\nrf_pred = rf_clf.predict(X_valid)\nprint(\"RandomForestClassifier's roc_auc_score : {0:.4f}\".format(roc_auc_score(y_valid, rf_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_clf = LogisticRegression()\nlr_clf.fit(X_train, y_train)\nlr_pred = lr_clf.predict(X_valid)\nprint(\"LogisticRegression's roc_auc_score : {0:.4f}\".format(roc_auc_score(y_valid, lr_pred)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}