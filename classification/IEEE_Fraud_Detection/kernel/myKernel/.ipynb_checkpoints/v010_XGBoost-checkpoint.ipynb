{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SlackNotifier.notifier import SlackNotifier\n",
    "\n",
    "api_url = 'https://hooks.slack.com/services/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'\n",
    "channel = '#ieee-cis-fraud-detection'\n",
    "sn = SlackNotifier(api_url, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'test_identity.csv', 'test_transaction.csv', 'train_identity.csv', 'train_transaction.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "print(os.listdir('../../input'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_t = pd.read_csv('../../input/train_transaction.csv', index_col='TransactionID')\n",
    "df_train_i = pd.read_csv('../../input/train_identity.csv', index_col='TransactionID')\n",
    "df_test_t = pd.read_csv('../../input/test_transaction.csv', index_col='TransactionID')\n",
    "df_test_i = pd.read_csv('../../input/test_identity.csv', index_col='TransactionID')\n",
    "sample_submission = pd.read_csv('../../input/sample_submission.csv')\n",
    "\n",
    "print('train_transaction의 shape : ', df_train_t.shape)\n",
    "print('train_identity의 shape : ', df_train_i.shape)\n",
    "print('test_transaction의 shape : ', df_test_t.shape)\n",
    "print('test_transaction의 shape : ', df_test_i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_t.merge(df_train_i, \n",
    "                            how='left', \n",
    "                            left_index=True, \n",
    "                            right_index=True)\n",
    "df_test = df_test_t.merge(df_test_i, \n",
    "                          how='left', \n",
    "                          left_index=True, \n",
    "                          right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Reduce Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = reduce_mem_usage(df_train)\n",
    "df_test = reduce_mem_usage(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Divide Features by Categorical and Numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_col_t : categorical columns in transaction dataset\n",
    "cat_col_t = ['ProductCD','addr1','addr2', 'P_emaildomain', 'R_emaildomain', 'TransactionDT']\n",
    "cat_col_t.extend(['card' + str(x) for x in range(1,7)]) # card1 ~ card6\n",
    "cat_col_t.extend(['M' + str(x) for x in range(1,10)]) # M1 ~ M9\n",
    "\n",
    "# cat_col_i : categorical columns in identity dataset\n",
    "cat_col_i = ['DeviceType', 'DeviceInfo']\n",
    "cat_col_i.extend(['id_' + str(x) for x in range(12, 39)]) # id_12 ~ id_38\n",
    "\n",
    "# cat_col : categorical columns in transaction and identity dataset\n",
    "cat_col = [*cat_col_t, *cat_col_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_col_t : numerical columns in transaction dataset\n",
    "num_col_t = [col for col in list(df_train_t.columns) if col not in [*cat_col_t, 'isFraud']]\n",
    "\n",
    "# num_col_i : numerical columns in identity dataset\n",
    "num_col_i = [col for col in list(df_train_i.columns) if col not in cat_col_i]\n",
    "\n",
    "# num_col : numerical columns in transaction and identity dataset\n",
    "num_col =[*num_col_t, *num_col_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Transaction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of transaction dataset's columns : \", df_train_t.shape[1])\n",
    "print(\"cat_col_t's length : \", len(cat_col_t))\n",
    "print(\"num_col_t's length : \", len(num_col_t))\n",
    "print(\"sum of boths : \", len(cat_col_t) + len(num_col_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4 Identity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of transaction dataset's columns : \", df_train_i.shape[1])\n",
    "print(\"cat_col_i's length : \", len(cat_col_i))\n",
    "print(\"num_col_i's length : \", len(num_col_i))\n",
    "print(\"sum of boths : \", len(cat_col_i) + len(num_col_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Summary of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Summary of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cat_summary(df, features) :\n",
    "\n",
    "    summary = df[features].dtypes.reset_index()\n",
    "    summary.rename(columns={'index': 'Name', 0: 'Dtype'}, inplace=True)\n",
    "    summary['DataSets'] = ['transaction' if col in cat_col_t else 'identity' for col in features]\n",
    "    summary['NullCnt'] = [df[col].isnull().sum() for col in features]\n",
    "    summary['NullRt'] = [np.round((df[col].isnull().sum())/df.shape[0], 2) for col in features]\n",
    "    summary['UniqueCnt'] = [df[col].nunique() for col in features]\n",
    "    Values = []\n",
    "    for col in features :\n",
    "        if df[col].nunique() <= 5 :\n",
    "            val = list(df[col].value_counts().reset_index()['index'])\n",
    "            val.sort()\n",
    "            Values.append(', '.join(str(v) for v in val))\n",
    "        else :\n",
    "            Values.append('-')    \n",
    "    summary['Values'] = Values\n",
    "    summary['MinValue'] = [df.loc[df[col].notnull(), col].min() for col in features]\n",
    "    summary['MaxValue'] = [df.loc[df[col].notnull(), col].max() for col in features]\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_summary = make_cat_summary(df_train, cat_col)\n",
    "cat_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Summary of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_num_summary(df, features) :\n",
    "    \n",
    "    summary = df[features].dtypes.reset_index()\n",
    "    summary.rename(columns={'index': 'Name', 0: 'Dtype'}, inplace=True)\n",
    "    summary['DataSets'] = ['transaction' if col in num_col_t else 'identity' for col in features]\n",
    "    summary['NullCnt'] = [df[col].isnull().sum() for col in features]\n",
    "    summary['NullRt'] = [np.round((df[col].isnull().sum())/df.shape[0], 2) for col in features]\n",
    "    summary['MinValue'] = [df.loc[df[col].notnull(), col].min() for col in features]\n",
    "    summary['Q25'] = [df[col].quantile([0.25]).values[0] for col in features]\n",
    "    summary['Q50'] = [df[col].quantile([0.50]).values[0] for col in features]\n",
    "    summary['Q75'] = [df[col].quantile([0.75]).values[0] for col in features]\n",
    "    summary['MaxValue'] = [df.loc[df[col].notnull(), col].max() for col in features]\n",
    "    summary['Mean'] = [df.loc[df[col].notnull(), col].mean() for col in features]\n",
    "    summary['Std'] = [df.loc[df[col].notnull(), col].std() for col in features]\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_summary = make_num_summary(df_train, num_col)\n",
    "num_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_acc_freq(df, col) :\n",
    "        \n",
    "    df_vc = df[col].value_counts().reset_index()\n",
    "    df_vc.rename(columns={'index': 'value', col: 'cnt'}, inplace=True)\n",
    "    df_vc['accCntRt'] = df_vc['cnt'].cumsum() / len(df[df[col].notnull()])\n",
    "    \n",
    "    return df_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_to_others(df, col, rate=None, cnt=None) :\n",
    "    \n",
    "    df_vc = df[col].value_counts().reset_index()\n",
    "    df_vc.rename(columns={'index': 'value', col: 'cnt'}, inplace=True)\n",
    "    df_vc['accCntRt'] = df_vc['cnt'].cumsum() / len(df[df[col].notnull()])\n",
    "    target_list = []\n",
    "    \n",
    "    if rate != None :\n",
    "        target_list = list(df_vc[df_vc['accCntRt'] >= float(rate)]['value'])\n",
    "    if cnt != None :\n",
    "        target_list = list(df_vc[df_vc['cnt'] < int(10)]['value'])\n",
    "        \n",
    "    dataType = str(df_vc['value'].values.dtype)\n",
    "    replace_value = 'OTHERS'\n",
    "    if dataType.find('int') == 0 :\n",
    "        replace_value = int(99999)\n",
    "    elif dataType.find('float') == 0 :\n",
    "        replace_value = float(99999)\n",
    "    \n",
    "    df.loc[df[col].isin(target_list), col] = replace_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Feature Engineering for Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_feature_engineering(df) :\n",
    "    # addr1\n",
    "    replace_to_others(df, 'addr1', rate=0.95)\n",
    "\n",
    "    # addr2\n",
    "    replace_to_others(df, 'addr2', cnt=10)\n",
    "\n",
    "    # P_emaildomain\n",
    "    df.loc[df['P_emaildomain'].str.contains('gmail', na=False), 'P_emaildomain'] = 'GMAIL'\n",
    "    df.loc[df['P_emaildomain'].str.contains('yahoo', na=False), 'P_emaildomain'] = 'YAHOO'\n",
    "    df.loc[df['P_emaildomain'].str.contains('hotmail', na=False), 'P_emaildomain'] = 'HOTMAIL'\n",
    "    df.loc[df['P_emaildomain'].str.contains('live', na=False), 'P_emaildomain'] = 'LIVE'\n",
    "    df.loc[df['P_emaildomain'].str.contains('netzero', na=False), 'P_emaildomain'] = 'NETZERO'\n",
    "    df.loc[df['P_emaildomain'].str.contains('outlook', na=False), 'P_emaildomain'] = 'OUTLOOK'\n",
    "    replace_to_others(df, 'P_emaildomain', cnt=250)\n",
    "\n",
    "    # R_emaildomain\n",
    "    df.loc[df['R_emaildomain'].str.contains('gmail', na=False), 'R_emaildomain'] = 'GMAIL'\n",
    "    df.loc[df['R_emaildomain'].str.contains('yahoo', na=False), 'R_emaildomain'] = 'YAHOO'\n",
    "    df.loc[df['R_emaildomain'].str.contains('hotmail', na=False), 'R_emaildomain'] = 'HOTMAIL'\n",
    "    df.loc[df['R_emaildomain'].str.contains('live', na=False), 'R_emaildomain'] = 'LIVE'\n",
    "    df.loc[df['R_emaildomain'].str.contains('netzero', na=False), 'R_emaildomain'] = 'NETZERO'\n",
    "    df.loc[df['R_emaildomain'].str.contains('outlook', na=False), 'R_emaildomain'] = 'OUTLOOK'\n",
    "    replace_to_others(df, 'R_emaildomain', cnt=80)\n",
    "\n",
    "    # TransactionDT\n",
    "    # Reference : https://www.kaggle.com/shkim4738/extensive-eda-and-modeling-xgb-hyperopt\n",
    "    import datetime\n",
    "\n",
    "    START_DATE = '2017-12-01'\n",
    "    startdate = datetime.datetime.strptime(START_DATE, '%Y-%m-%d')\n",
    "    df['Date'] = df['TransactionDT'].apply(lambda x : (startdate + datetime.timedelta(seconds=x)))\n",
    "\n",
    "    df['Weekdays'] = df['Date'].dt.dayofweek\n",
    "    df['Hours'] = df['Date'].dt.hour\n",
    "    df['Days'] = df['Date'].dt.day\n",
    "\n",
    "    df.drop(['Date'], axis=1, inplace=True)\n",
    "\n",
    "    # DeviceInfo\n",
    "    df.loc[df['DeviceInfo'].str.contains('SAMSUNG', na=False), 'DeviceInfo'] = 'SAMSUNG'\n",
    "    df.loc[df['DeviceInfo'].str.contains('SM', na=False), 'DeviceInfo'] = 'SM'\n",
    "    df.loc[df['DeviceInfo'].str.contains('rv', na=False), 'DeviceInfo'] = 'RV'\n",
    "    df.loc[df['DeviceInfo'].str.contains('Moto', na=False), 'DeviceInfo'] = 'MOTO'\n",
    "    df.loc[df['DeviceInfo'].str.contains('HUAWEI', na=False), 'DeviceInfo'] = 'HUAWEI'\n",
    "    df.loc[df['DeviceInfo'].str.contains('Huawei', na=False), 'DeviceInfo'] = 'HUAWEI'\n",
    "    df.loc[df['DeviceInfo'].str.contains('LG-', na=False), 'DeviceInfo'] = 'LG'\n",
    "    df.loc[df['DeviceInfo'].str.contains('Android', na=False), 'DeviceInfo'] = 'ANDROID'\n",
    "    df.loc[df['DeviceInfo'].str.contains('Linux', na=False), 'DeviceInfo'] = 'LINUX'\n",
    "    df.loc[df['DeviceInfo'].str.contains('HTC', na=False), 'DeviceInfo'] = 'HTC'\n",
    "    df.loc[df['DeviceInfo'].str.contains('Hisense', na=False), 'DeviceInfo'] = 'HISENSE'\n",
    "    df.loc[df['DeviceInfo'].str.contains('Blade', na=False), 'DeviceInfo'] = 'BLADE'\n",
    "    df.loc[df['DeviceInfo'].str.contains('BLADE', na=False), 'DeviceInfo'] = 'BLADE'\n",
    "    df.loc[df['DeviceInfo'].str.contains('ASUS', na=False), 'DeviceInfo'] = 'ASUS'\n",
    "    df.loc[df['DeviceInfo'].str.contains('Redmi', na=False), 'DeviceInfo'] = 'REDMI'\n",
    "    df.loc[df['DeviceInfo'].str.contains('iOS', na=False), 'DeviceInfo'] = 'iOS'\n",
    "    df.loc[df['DeviceInfo'].str.contains('MacOS', na=False), 'DeviceInfo'] = 'MacOS'\n",
    "    device = ['SAMSUNG','SM','RV','MOTO','HUAWEI','LG','ANDROID','LINUX','HTC','HISENSE','BLADE','ASUS','REDMI',\n",
    "              'Windows','iOS', 'MacOS', 'Trident/7.0']\n",
    "    df.loc[(~df['DeviceInfo'].isin(device)) & (df['DeviceInfo'].notnull()), 'DeviceInfo'] = 'OTHERS'\n",
    "\n",
    "    # id_30\n",
    "    df.loc[df['id_30'].str.contains('Windows', na=False), 'id_30'] = 'WINDOWS'\n",
    "    df.loc[df['id_30'].str.contains('iOS', na=False), 'id_30'] = 'iOS'\n",
    "    df.loc[df['id_30'].str.contains('Mac OS X', na=False), 'id_30'] = 'MacOS'\n",
    "    df.loc[df['id_30'].str.contains('Android', na=False), 'id_30'] = 'ANDROID'\n",
    "\n",
    "    # id_31\n",
    "    df.loc[df['id_31'].str.contains('chrome', na=False), 'id_31'] = 'CHROME'\n",
    "    df.loc[df['id_31'].str.contains('firefox', na=False), 'id_31'] = 'FIREFOX'\n",
    "    df.loc[df['id_31'].str.contains('edge', na=False), 'id_31'] = 'EDGE'\n",
    "    df.loc[df['id_31'].str.contains('ie ', na=False), 'id_31'] = 'IE'\n",
    "    df.loc[df['id_31'].str.contains('safari', na=False), 'id_31'] = 'SAFARI'\n",
    "    df.loc[df['id_31'].str.contains('opera', na=False), 'id_31'] = 'OPERA'\n",
    "    df.loc[df['id_31'].str.contains('samsung', na=False), 'id_31'] = 'SAMSUNG'\n",
    "    df.loc[df['id_31'].str.contains('Samsung', na=False), 'id_31'] = 'SAMSUNG'\n",
    "    df.loc[df['id_31'].str.contains('android', na=False), 'id_31'] = 'ANDROID'\n",
    "    df.loc[df['id_31'].str.contains('Android', na=False), 'id_31'] = 'ANDROID'\n",
    "    device2 = ['CHROME','FIREFOX','EDGE','IE','SAFARI','OPERA','SAMSUNG','ANDROID']\n",
    "    df.loc[(~df['id_31'].isin(device2)) & (df['id_31'].notnull()), 'id_31'] = 'OTHERS'\n",
    "\n",
    "    # id_33\n",
    "    replace_to_others(df, 'id_33', cnt=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feature_engineering(df_train)\n",
    "cat_feature_engineering(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_t.extend(['Weekdays','Hours','Days'])\n",
    "cat_col = [*cat_col_t, *cat_col_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Feature Engineering for Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_null_over90 = list(cat_summary.loc[cat_summary['NullRt'] >= float(0.9), 'Name'].values)\n",
    "num_col_null_over90 = list(num_summary.loc[num_summary['NullRt'] >= float(0.9), 'Name'].values)\n",
    "col_null_over90 = [*cat_col_null_over90, *num_col_null_over90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(col_null_over90, axis=1)\n",
    "df_test = df_test.drop(col_null_over90, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = [col for col in cat_col if col not in cat_col_null_over90]\n",
    "num_col = [col for col in num_col if col not in num_col_null_over90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_col :\n",
    "    if col in df_train.columns :\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(df_train[col].astype(str).values)\n",
    "               + list(df_test[col].astype(str).values))\n",
    "        df_train[col] = le.transform(list(df_train[col].astype(str).values))\n",
    "        df_test[col] = le.transform(list(df_test[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Set X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_targets = df_train['isFraud']\n",
    "X_features = df_train.drop('isFraud', axis=1)\n",
    "X_features = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Make Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_features, y_targets,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
