{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines-To-Start-With(LB=0.56+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fred Navruzov's Kernel](https://www.kaggle.com/frednavruzov/baselines-to-start-with-lb-0-56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi, Kagglers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hereafter I will try to publish **some basic approaches to climb up the Leaderboard.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Competition goal**\n",
    "\n",
    "In this competition, Daimler is challenging Kagglers to tackle the curse of dimensionality and reduce the time that cars spend on he test bench. Competitors will work with a dataset representing different permutations(순열, 치환) of Mercedes-Benz car features to predict the time it takes to pass testing. Winning algorithms will conribute to speedier testing, resulting in lower carbon dioxide(이산화탄소) emissions(배출) withou reducing Daimler's standards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Notebook adopts skeleton from (maybe?) this script:  \n",
    "[https://www.kaggle.com/ermolushka/starter-xgboost](https://www.kaggle.com/ermolushka/starter-xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stay tuned, this notebook will be updated on a regular basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P.s. Upvotes and comments would let me update it faster and in a more smart way :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##Before Label Encoding##\n",
      "Shape train: (4209, 378)\n",
      "Shape test: (4209, 377)\n",
      "--------------------------------------------\n",
      "##After Label Encoding##\n",
      "Shape train: (4209, 378)\n",
      "Shape test: (4209, 377)\n"
     ]
    }
   ],
   "source": [
    "# read datasets\n",
    "train = pd.read_csv(\"../../input/train.csv\")\n",
    "test = pd.read_csv(\"../../input/test.csv\")\n",
    "\n",
    "print(\"##Before Label Encoding##\")\n",
    "print(\"Shape train: {}\\nShape test: {}\".format(train.shape, test.shape))\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in train.columns :\n",
    "    if train[c].dtype == 'object' :\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[c].values) + list(test[c].values))\n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))\n",
    "        \n",
    "# shape\n",
    "print(\"##After Label Encoding##\")\n",
    "print(\"Shape train: {}\\nShape test: {}\".format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add decomposed(분해된) components(요소들): PCA / ICA etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, FastICA\n",
    "n_comp = 10\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=42)\n",
    "pca2_results_train = pca.fit_transform(train.drop([\"y\"], axis=1))\n",
    "pca2_results_test = pca.transform(test)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=42)\n",
    "ica2_results_train = ica.fit_transform(train.drop([\"y\"], axis=1))\n",
    "ica2_results_test = ica.transform(test)\n",
    "\n",
    "# Append decomposition components to datasets\n",
    "for i in range(1, n_comp+1) :\n",
    "    train['pca_' + str(i)] = pca2_results_train[:, i-1]\n",
    "    test['pca_' + str(i)] = pca2_results_test[:, i-1]\n",
    "    \n",
    "    train['ica_' + str(i)] = ica2_results_train[:, i-1]\n",
    "    test['ica_' + str(i)] = ica2_results_test[:, i-1]\n",
    "    \n",
    "y_train = train['y']\n",
    "y_mean = np.mean(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:12.6401\ttest-rmse:12.6387\n",
      "[50]\ttrain-rmse:11.0905\ttest-rmse:11.1527\n",
      "[100]\ttrain-rmse:10.0181\ttest-rmse:10.1487\n",
      "[150]\ttrain-rmse:9.28978\ttest-rmse:9.48862\n",
      "[200]\ttrain-rmse:8.8028\ttest-rmse:9.06727\n",
      "[250]\ttrain-rmse:8.47773\ttest-rmse:8.80199\n",
      "[300]\ttrain-rmse:8.25941\ttest-rmse:8.63741\n",
      "[350]\ttrain-rmse:8.09155\ttest-rmse:8.53632\n",
      "[400]\ttrain-rmse:7.95297\ttest-rmse:8.47684\n",
      "[450]\ttrain-rmse:7.83878\ttest-rmse:8.44109\n",
      "[499]\ttrain-rmse:7.73445\ttest-rmse:8.42257\n",
      "500\n",
      "[20:23:40] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "()# mmm, xgboost, loved by everyone ^-^\n",
    "import xgboost as xgb\n",
    "\n",
    "# Prepare dict of params for xgboost to run with\n",
    "xgb_params = {\n",
    "    'n_trees': 500,\n",
    "    'eta': 0.005,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.95,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'base_score': y_mean, # base prediction = mean(target)\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "# form DMatrices for Xgboost training\n",
    "dtrain = xgb.DMatrix(train.drop('y', axis=1), y_train)\n",
    "dtest = xgb.DMatrix(test)\n",
    "\n",
    "# xgboost, cross-validation\n",
    "cv_result = xgb.cv(xgb_params,\n",
    "                   dtrain,\n",
    "                   num_boost_round=500, # increase to have better results (~700)\n",
    "                   early_stopping_rounds=50,\n",
    "                   verbose_eval=50,\n",
    "                   show_stdv=False)\n",
    "\n",
    "num_boost_rounds = len(cv_result)\n",
    "print(num_boost_rounds)\n",
    "\n",
    "# train model\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6108367775830508\n"
     ]
    }
   ],
   "source": [
    "# check f2-score (to get higher score - increase num_boost_round in previous cell)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# now fixed, correct calculation\n",
    "print(r2_score(dtrain.get_label(), model.predict(dtrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions and save results\n",
    "y_pred = model.predict(dtest)\n",
    "output = pd.DataFrame({'id': test['ID'].astype(np.int32),\n",
    "                       'y': y_pred})\n",
    "output.to_csv('xgboost-depth{}-pca-ica.csv'.format(xgb_params['max_depth']), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stay tuned, this notebook will be updated on a regular basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P.s. Upvotes and comments would let me update it faster and in a more smart way :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
